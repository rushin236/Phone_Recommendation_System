{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone Recommender Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Imarticus_Learning\\\\12_Projects\\\\Phone_Recommendation_System\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Imarticus_Learning\\\\12_Projects\\\\Phone_Recommendation_System'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainConfig:\n",
    "    root_dir: Path\n",
    "    model_file: Path\n",
    "    tokenizer_file: Path\n",
    "    transform_data_file: Path\n",
    "    model_evaluation_file: Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainParams:\n",
    "    embedding_dim: int\n",
    "    output_classes: int\n",
    "    epochs: int\n",
    "    batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.phone_recommender.constants import *\n",
    "from src.phone_recommender.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH) -> None:\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "    def get_model_build_config(self):\n",
    "        config = self.config.model_training\n",
    "        params = self.params.parameters\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_train_config = ModelTrainConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_file=config.model_file,\n",
    "            tokenizer_file=config.tokenizer_file,\n",
    "            transform_data_file=config.transform_data_file,\n",
    "            model_evaluation_file=config.model_evaluation_file,\n",
    "        )\n",
    "\n",
    "        model_train_params = ModelTrainParams(\n",
    "            embedding_dim=params.embedding_dim,\n",
    "            output_classes=params.output_classes,\n",
    "            epochs=params.epochs,\n",
    "            batch_size=params.batch_size,\n",
    "        )\n",
    "\n",
    "        return model_train_config, model_train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-11 23:24:57,106: WARNING: module_wrapper: From d:\\Imarticus_Learning\\12_Projects\\Phone_Recommendation_System\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from src.phone_recommender.logging import logger\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config=ModelTrainConfig, params=ModelTrainParams) -> None:\n",
    "        self.config = config\n",
    "        self.params = params\n",
    "\n",
    "    def get_transformed_data(self):\n",
    "        transform_data_file = self.config.transform_data_file\n",
    "        if not os.path.exists(transform_data_file):\n",
    "            logger.info(\"No transform data file please check if data transform is complete\")\n",
    "        else:\n",
    "            df = pd.read_csv(self.config.transform_data_file)\n",
    "            return df\n",
    "\n",
    "    def build_model(self, df: pd.DataFrame):\n",
    "        text = list(df['text'])\n",
    "        clusters = df['class']\n",
    "\n",
    "        # Initialize the Tokenizer\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(text)\n",
    "\n",
    "        # Convert text to sequences of integers\n",
    "        sequences = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "        # Pad sequences to make them of equal length (required for neural networks)\n",
    "        max_sequence_length = max(map(len, sequences))\n",
    "        print(max_sequence_length)\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "        # Data Sampling\n",
    "        X = pd.DataFrame(padded_sequences)\n",
    "        X.head()\n",
    "\n",
    "        y = to_categorical(clusters)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        embedding_dim = self.params.embedding_dim\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "        output_classes = self.params.output_classes\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=X.shape[1]))\n",
    "        model.add(LSTM(100))\n",
    "        model.add(Dense(output_classes, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "\n",
    "        # Train the model\n",
    "        epochs = self.params.epochs\n",
    "        batch_size = self.params.batch_size\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        y_test1 = np.argmax(y_test, axis=1)\n",
    "\n",
    "        print(classification_report(y_test1, pred))\n",
    "\n",
    "        accuracy = model.evaluate(X_test, y_test)[1]\n",
    "        with open(self.config.model_evaluation_file, \"w\") as f:\n",
    "            f.write(\n",
    "                f'Test Accuracy: {accuracy * 100:.2f}%\\nClassification Report:\\n{classification_report(y_test1, pred)}'\n",
    "            )\n",
    "\n",
    "        return model, tokenizer\n",
    "\n",
    "    def save_model_tokenizer(self, model: Sequential, tokenizer: Tokenizer):\n",
    "        model.save(self.config.model_file)\n",
    "\n",
    "        # Save the tokenizer using pickle\n",
    "        tokenizer_file = self.config.tokenizer_file\n",
    "\n",
    "        with open(tokenizer_file, 'wb') as handle:\n",
    "            pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-11 23:24:58,113: INFO: common: yaml file: config\\config.yaml loads successfully]\n",
      "[2023-12-11 23:24:58,115: INFO: common: yaml file: params.yaml loads successfully]\n",
      "[2023-12-11 23:24:58,116: INFO: common: created directory at : artifacts/model_training]\n",
      "50\n",
      "[2023-12-11 23:24:58,409: WARNING: module_wrapper: From d:\\Imarticus_Learning\\12_Projects\\Phone_Recommendation_System\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "]\n",
      "[2023-12-11 23:24:58,841: WARNING: module_wrapper: From d:\\Imarticus_Learning\\12_Projects\\Phone_Recommendation_System\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 50)            27450     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               60400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88153 (344.35 KB)\n",
      "Trainable params: 88153 (344.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/35\n",
      "[2023-12-11 23:24:59,472: WARNING: module_wrapper: From d:\\Imarticus_Learning\\12_Projects\\Phone_Recommendation_System\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "]\n",
      "[2023-12-11 23:24:59,953: WARNING: module_wrapper: From d:\\Imarticus_Learning\\12_Projects\\Phone_Recommendation_System\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "]\n",
      "37/37 [==============================] - 4s 37ms/step - loss: 0.9305 - accuracy: 0.4820 - val_loss: 0.6468 - val_accuracy: 0.6804\n",
      "Epoch 2/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.5594 - accuracy: 0.7113 - val_loss: 0.4721 - val_accuracy: 0.7801\n",
      "Epoch 3/35\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.4376 - accuracy: 0.7844 - val_loss: 0.3359 - val_accuracy: 0.8144\n",
      "Epoch 4/35\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.2872 - accuracy: 0.9089 - val_loss: 0.1948 - val_accuracy: 0.9725\n",
      "Epoch 5/35\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.2038 - accuracy: 0.9519 - val_loss: 0.1883 - val_accuracy: 0.9519\n",
      "Epoch 6/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.2088 - accuracy: 0.9416 - val_loss: 0.2085 - val_accuracy: 0.9347\n",
      "Epoch 7/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.1593 - accuracy: 0.9613 - val_loss: 0.2366 - val_accuracy: 0.9416\n",
      "Epoch 8/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.1821 - accuracy: 0.9450 - val_loss: 0.1856 - val_accuracy: 0.9588\n",
      "Epoch 9/35\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.0982 - accuracy: 0.9768 - val_loss: 0.1036 - val_accuracy: 0.9656\n",
      "Epoch 10/35\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.0608 - accuracy: 0.9854 - val_loss: 0.1335 - val_accuracy: 0.9656\n",
      "Epoch 11/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0682 - accuracy: 0.9845 - val_loss: 0.1521 - val_accuracy: 0.9622\n",
      "Epoch 12/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0639 - accuracy: 0.9837 - val_loss: 0.1107 - val_accuracy: 0.9725\n",
      "Epoch 13/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.1108 - val_accuracy: 0.9691\n",
      "Epoch 14/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0455 - accuracy: 0.9888 - val_loss: 0.1069 - val_accuracy: 0.9622\n",
      "Epoch 15/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.0839 - val_accuracy: 0.9691\n",
      "Epoch 16/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0259 - accuracy: 0.9940 - val_loss: 0.2107 - val_accuracy: 0.9656\n",
      "Epoch 17/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0351 - accuracy: 0.9905 - val_loss: 0.1366 - val_accuracy: 0.9622\n",
      "Epoch 18/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.1436 - val_accuracy: 0.9725\n",
      "Epoch 19/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0673 - accuracy: 0.9759 - val_loss: 0.0899 - val_accuracy: 0.9794\n",
      "Epoch 20/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0224 - accuracy: 0.9914 - val_loss: 0.1115 - val_accuracy: 0.9691\n",
      "Epoch 21/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.1373 - val_accuracy: 0.9691\n",
      "Epoch 22/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.0889 - val_accuracy: 0.9759\n",
      "Epoch 23/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.1204 - val_accuracy: 0.9588\n",
      "Epoch 24/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.1872 - val_accuracy: 0.9691\n",
      "Epoch 25/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0340 - accuracy: 0.9948 - val_loss: 0.1332 - val_accuracy: 0.9725\n",
      "Epoch 26/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.1643 - val_accuracy: 0.9553\n",
      "Epoch 27/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.1632 - val_accuracy: 0.9794\n",
      "Epoch 28/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.1668 - val_accuracy: 0.9794\n",
      "Epoch 29/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1879 - val_accuracy: 0.9759\n",
      "Epoch 30/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.2482 - val_accuracy: 0.9691\n",
      "Epoch 31/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.1376 - val_accuracy: 0.9656\n",
      "Epoch 32/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0559 - accuracy: 0.9863 - val_loss: 0.1193 - val_accuracy: 0.9691\n",
      "Epoch 33/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.1354 - val_accuracy: 0.9725\n",
      "Epoch 34/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.1132 - val_accuracy: 0.9691\n",
      "Epoch 35/35\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.0124 - accuracy: 0.9948 - val_loss: 0.1504 - val_accuracy: 0.9725\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96        78\n",
      "           1       0.92      0.99      0.95       124\n",
      "           2       1.00      0.96      0.98       162\n",
      "\n",
      "    accuracy                           0.97       364\n",
      "   macro avg       0.97      0.96      0.97       364\n",
      "weighted avg       0.97      0.97      0.97       364\n",
      "\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1844 - accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Imarticus_Learning\\12_Projects\\Phone_Recommendation_System\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_build_config, model_params_config = config.get_model_build_config()\n",
    "    model_trainer = ModelTrainer(model_build_config, model_params_config)\n",
    "    df = model_trainer.get_transformed_data()\n",
    "    model, tokenizer = model_trainer.build_model(df)\n",
    "    model_trainer.save_model_tokenizer(model, tokenizer)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
